## 2.6特征分解

### 1.特征值与特征向量

#### 定义：

设A是n阶方阵，若数λ和n维非零列向量x，使得
$$ {1}
Ax=λx
$$
则称**λ**是方阵A的一个**特征值**，**x**为方阵A的对应于特征值λ的一个**特征向量**



用特征分解去分析矩阵A时，得到特征向量x构成的矩阵vecs和特征值构成的向量vals；
$$
A=vecs×vals×vecs^{-1}
$$


#### 几何意义：

- ##### 在![\vec{i},\vec{j}](https://private.codecogs.com/gif.latex?%5Cvec%7Bi%7D%2C%5Cvec%7Bj%7D)为基向量的空间下有个向量![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D):

  ![img](https://img-blog.csdn.net/20180830104637244?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNzQyMDA5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- ##### 对![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)随便左乘一个矩阵![A](https://private.codecogs.com/gif.latex?A)，即对![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)进行一个线性变换：

  ![img](https://img-blog.csdn.net/20180830113243904?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNzQyMDA5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- ##### 调整下![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)的方向，使其特殊一点

  ![img](https://img-blog.csdn.net/20180830113439150?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNzQyMDA5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

可以观察到，调整后的![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)和![A\vec{v}](https://private.codecogs.com/gif.latex?A%5Cvec%7Bv%7D)在同一直线上，只是![A\vec{v}](https://private.codecogs.com/gif.latex?A%5Cvec%7Bv%7D)的长度相对![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)的长度变长了。

此时，我们就称![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)是![A](https://private.codecogs.com/gif.latex?A)的特征向量，而![A\vec{v}](https://private.codecogs.com/gif.latex?A%5Cvec%7Bv%7D)的长度是![\vec{v}](https://private.codecogs.com/gif.latex?%5Cvec%7Bv%7D)的长度的![\lambda](https://private.codecogs.com/gif.latex?%5Clambda)倍，![\lambda](https://private.codecogs.com/gif.latex?%5Clambda)就是特征值。

 即    ![T(\vec{v}) = A\vec{v} = \lambda \vec{v}](https://private.codecogs.com/gif.latex?T%28%5Cvec%7Bv%7D%29%20%3D%20A%5Cvec%7Bv%7D%20%3D%20%5Clambda%20%5Cvec%7Bv%7D)

- ##### 从特征向量和特征值的定义中还可以看出，特征向量所在直线上的向量都是特征向量。

  ![img](https://img-blog.csdn.net/20180830123421670?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNzQyMDA5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 2.Python代码实现及验证

#### numpy中的eig函数返回

```python
import numpy as np
C=np.random.randint(-10,10,(4,4))
A=np.dot(C.T,C)
print(A)#生成正定对称矩阵

vals,vecs=np.linalg.eig(A)
print(vals)
print(vecs)#返回矩阵A的特征值组成的向量vals，特征向量组成的矩阵vecs
```

#### 结果验证

```python
x=np.dot(A,vecs[:,0])
y=np.dot(vals[0],vecs[:,0])
print(x,"\n",y)#验证Ax=λx

Lambda=np.diag(vals)
x=numpy.linalg.inv(vecs)
B=np.dot(np.dot(vecs,Lambda),x)
print(B)
```

