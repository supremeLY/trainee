

# 3.11最大似然估计法 -张满满.md

#解决的问题：

-它是建立在极大似然原理的基础上的一个统计方法，极大似然原理的直观想法是，一个随机试验如有若干个可能的结果A，B，C，... ，若在一次试验中，结果A出现了，那么可以认为实验条件对A的出现有利，也即出现的概率P(A)较大。极大似然原理的直观想法我们用下面例子说明。设甲箱中有99个白球，1个黑球；乙箱中有1个白球．99个黑球。现随机取出一箱，再从抽取的一箱中随机取出一球，结果是黑球，这一黑球从乙箱抽取的概率比从甲箱抽取的概率大得多，这时我们自然更多地相信这个黑球是取自乙箱的。一般说来，事件A发生的概率与某一未知参数  有关， 
取值不同，则事件A发生的概率 
也不同，当我们在一次试验中事件A发生了，则认为此时的  值应是t的一切可能取值中使 
达到最大的那一个，极大似然估计法就是要选取这样的t值作为参数t的估计值，使所选取的样本在被选的总体中出现的可能性为最大。 

-极大似然估计，只是一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。极大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。当然极大似然估计只是一种粗略的数学期望，要知道它的误差大小还要做区间估计

-在已经得到试验结果的情况下，我们应该寻找使这个结果出现的可能性最大的那个参数 
 作为真 参数 的估计

#例题

•![1566977183657](C:\Users\这不是你的电脑\AppData\Roaming\Typora\typora-user-images\1566977183657.png)

•以伯努利分布（Bernoulli distribution，又叫做两点分布或0-1分布）为例：

•也可以写成以下形式： 

![1566977193667](C:\Users\这不是你的电脑\AppData\Roaming\Typora\typora-user-images\1566977193667.png)

•这里注意区分 f(x;p)f(x;p) 与前面的条件概率的区别，引号后的 pp 仅表示 ff 依赖于 pp 的值，pp 并不是 ff 的前置条件，而只是这个概率分布的一个参数而已，也可以省略引号后的内容：

•

![1566977203392](C:\Users\这不是你的电脑\AppData\Roaming\Typora\typora-user-images\1566977203392.png)





![1566977373481](C:\Users\这不是你的电脑\AppData\Roaming\Typora\typora-user-images\1566977373481.png)





似然函数的最大值

似然函数的最大值意味着什么？让我们回到概率和似然的定义，概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越

#实例代码



import numpy as np
import matplotlib.pyplot as plt

fig = plt.figure()
mu = 30  # mean of distribution
sigma = 2  # standard deviation of distribution
x = mu + sigma * np.random.randn(10000)

def mle(x):
    """
    极大似然估计
    :param x:
    :return:
    """
    u = np.mean(x)
    return u, np.sqrt(np.dot(x - u, (x - u).T) / x.shape[0])

print(mle(x))
num_bins = 100
plt.hist(x, num_bins)
plt.show()